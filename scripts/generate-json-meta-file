#!/usr/bin/env python3

import argparse
import json
import os
import sys
import time
import datetime
import subprocess
import pprint

# I just like having a class with "my" info
class MyInfo:
	# Not super precise, but goot enough for government work.
	_t0 = datetime.datetime.now()
	_cwd = os.getcwd()

	def init_class(self):
		pre = "pico nano micro milli n kilo mega giga tera peta exa zetta yotta".split()
		MyInfo.prefixes = pre
		start = -12
		MyInfo.pre_min = 1.0 * 10**start
		MyInfo.pre_max = MyInfo.pre_min
		MyInfo.prefix2val = {}
		MyInfo.val2long = {}
		MyInfo.val2short = {}
		MyInfo.magnitutes = []
		for prefix in pre:
			short = prefix[0].upper()
			current = 1.0 * 10**start
			MyInfo.pre_max = current
			MyInfo.magnitutes.append(current)
			MyInfo.prefix2val[prefix] = current
			MyInfo.prefix2val[short] = current
			MyInfo.val2long[current] = prefix
			MyInfo.val2short[current] = short
			start += 3
			pass
		pass

	def __init__(self):
		self.t0 = MyInfo._t0
		self.initial_dir = MyInfo._cwd
		# This is the "real" filename. If it was called with a symlink, this
		# will point to the target file not the symlink
		self.real_filename = os.path.realpath(__file__)
		# This is the filename of the called script which may not be the same
		# as the "real" filename
		self.filename = os.path.abspath(__file__)
		self.basename = os.path.basename(__file__)
		self.dir = os.path.dirname(os.path.abspath(__file__))
		self.simestamp = time.strftime("%Y%m%d-%H%M%S")
		self.secs_per_minute = 60
		self.secs_per_hour = 3600
		self.secs_per_day = self.secs_per_hour * 24
		self.secs_per_week = self.secs_per_day * 7
		self.secs_per_year = self.secs_per_day * 365.25
		self.secs_per_month = self.secs_per_year / 12
		self.init_class()
		pass

	def now(self):
		return datetime.datetime.now()

	def elapsed(self,tn=None,t0=None):
		if tn is None:
			tn = self.now()
			pass
		if t0 is None:
			t0 = self.t0
			pass
		return (tn - t0).total_seconds()

	def pbytes(self,num):
		if num >= 1000000000000:
			return "%0.2fTB" %(num / 1000000000000)
		if num >= 1000000000:
			return "%0.2fGB" %(num / 1000000000)
		if num >= 1000000:
			return "%0.2fMB" %(num / 1000000)
		if  num >= 1000:
			return "%0.2fKB" %(num / 1000)
		return "%3s Bytes" %(num)

	def pnum(self,num):
		if num >= 1000000000:
			return "%0.2fG" %(num / 1000000000)
		if num >= 1000000:
			return "%0.2fM" %(num / 1000000)
		if  num >= 1000:
			return "%0.2fK" %(num / 1000)
		return "%3s " %(num)


	def psecs(self, secs):
		if secs >= self.secs_per_year:
			secs = secs / self.secs_per_year
			return f"{secs:0.2f} Years"
		if secs >= self.secs_per_month:
			secs = secs / self.secs_per_month
			return f"{secs:0.2f} Months"
		if secs >= self.secs_per_week:
			secs = secs / self.secs_per_week
			return f"{secs:0.2f} Weeks"
		if secs >= self.secs_per_day:
			secs = secs / self.secs_per_day
			return f"{secs:0.2f} Days"
		if secs >= self.secs_per_hour:
			secs = secs / self.secs_per_hour
			return f"{secs:0.2f} Hours"
		if secs >= self.secs_per_minute:
			secs = secs / self.secs_per_minute
			return f"{secs:0.2f} Minutes"
		return f"{secs:0.2f} Secs"

	def rate(self,count,tn=None,t0=None,total=None,append=""):
		secs = self.elapsed(tn,t0)
		rate = count / secs
		if total is not None:
			secs_remain = (total - count) / rate
			percent = f"{count * 100 / total:0.2f}"
			estimate = self.psecs(secs_remain)
			estimate = f" ({me.pnum(count)} of {me.pnum(total)} {percent}% ~ {estimate} Remaining)"
		else:
			estimate = ""
			pass
		if rate <= 1.0 / self.secs_per_year:
			return f"{rate * self.secs_per_year:0.2f}/Year{estimate}"
		if rate <= 1.0 / self.secs_per_month:
			return f"{rate * self.secs_per_week:0.2f}/Month{estimate}"
		if rate <= 1.0 / self.secs_per_week:
			return f"{rate * self.secs_per_week:0.2f}/Week{estimate}"
		if rate <= 1.0 / self.secs_per_week:
			return f"{rate * self.secs_per_day:0.2f}/Day{estimate}"
		if rate <= 1.0 / self.secs_per_hour:
			return f"{rate * self.secs_per_hour:0.2f}/Hour{estimate}"
		if rate <= 1.0 / self.secs_per_minute:
			return f"{rate * self.secs_per_minute:0.2f}/Minute{estimate}"
		if rate >= 1000:
			rate = self.pnum(rate)
			pass
		return f"{rate}{append}/Sec{estimate}"
	pass
me = MyInfo()

class PushShiftBase:
	def __init__(self):
		self.data = {
			"input_file_name":"",
			"record_count":0,
			"input_file_size":0,
			"data_size":0,
			"value_types":{},
			"attributes":{},
			}
		self.attribs = self.data["attributes"]
		self.value_types = self.data["value_types"]
		self.data["record_count"] = 0
		pass

	def track_types(self,type_info,vtype,value,size):
		if vtype not in type_info:
			if "int" == vtype or "float" == vtype:
				type_info[vtype] = {
					"count":0,
					"min":value,
					"max":value,
					"sum":0,
				}
			elif "str" == vtype or "list" == vtype:
				type_info[vtype] = {
					"count":0,
					"min_length":size,
					"max_length":size,
					"length_sum":0,
				}
			elif "dict" == vtype:
				type_info[vtype] = {
					"count":0,
					"min_keys":size,
					"max_keys":size,
					"key_sum":0,
				}
			elif "bool" == vtype:
				type_info[vtype] = {
					"count":0,
					"true":0,
					"false":0,
				}
			else:
				type_info[vtype] = {
					"count":0,
					}
				pass
			pass
		type_info = type_info[vtype]
		type_info["count"] += 1
		if "int" == vtype or "float" == vtype:
			if value < type_info["min"]:
				type_info["min"] = value
			if value > type_info["max"]:
				type_info["max"] = value
			type_info["sum"] += value
			pass
		elif "str" == vtype or "list" == vtype:
			if size < type_info["min_length"]:
				type_info["min_length"] = size
			if size > type_info["max_length"]:
				type_info["max_length"] = size
			type_info["length_sum"] += size
			pass
		elif "dict" == vtype:
			key_count = len(value.keys())
			if key_count < type_info["min_keys"]:
				type_info["min_keys"] = key_count
			if key_count > type_info["max_keys"]:
				type_info["max_keys"] = key_count
			type_info["key_sum"] += key_count
			pass
		elif "bool" == vtype:
			if value:
				type_info["true"] += 1
			else:
				type_info["false"] += 1
		pass

	def track_attrib(self,key,value,size):
		if key not in self.attribs:
			self.attribs[key] = {
				"count":0,
				"size":0,
				"types": {}
				}
			pass
		vtype = type(value).__name__
		if "NoneType" == vtype:
			vtype = "null"
			pass
		self.track_types(self.attribs[key]["types"],vtype,value,size)
		self.track_types(self.value_types,vtype,value,size)
		self.attribs[key]["count"] += 1
		self.attribs[key]["size"] += size
		pass

	pass

class PushShiftFile(PushShiftBase):
	_ext2tool = {
		".bz2": ["bunzip2","-q","-c"],
		".zst": ["unzstd","-q","-c"],
		".gz": ["gunzip","-q","-c"],
		}
	def __init__(self,parent,filename):
		super().__init__()
		self.parent = parent
		self.args = parent.args
		self.filename = filename
		self.full_filename = os.path.realpath(os.path.join(filename))
		self.base, self.extension = os.path.splitext(self.full_filename)
		print(f"Will process '{self.full_filename}'.")
		self.size = os.path.getsize(self.full_filename)
		if self.extension in PushShiftFile._ext2tool:
			self.cmd = PushShiftFile._ext2tool[self.extension]
		else:
			self.cmd = None
		self.ext = self.extension
		self.data["subprocess"] = self.cmd
		self.data["input_file_name"] = os.path.basename(self.filename)
		#self.data["file_name"] = self.filename
		self.data["input_file_size"] = self.size
		self.json_file = f"{self.base}-meta.json"
		self.data["output_json_file"] = os.path.basename(self.json_file)
		self.processed = False
		self.last_save_count = 0
		pass

	def count_attribs(self,obj):
		for key,value in obj.items():
			size = len(str(value))
			self.track_attrib(key,value,size)
			#self.parent.track_attrib(key,value,size)
			pass
		pass

	def pnum(self,num):
		if num >= 1000000000:
			return "%3sG" %(num / 1000000000)
		if num >= 1000000:
			return "%3sM" %(num / 1000000)
		if  num >= 1000:
			return "%3sK" %(num / 1000)
		return "%3s " %(num)


	def show_progress(self):
		count = self.data["record_count"]
		args = self.args
		tn = datetime.datetime.now()
		secs = (tn - self.parent.tn).total_seconds()
		if secs < args.min_save_secs:
			return self
		if args.save_progress_each and count - self.last_save_count >= args.save_progress_each:
			self.last_save_count = count
			self.attr_info()
			pass
		self.parent.tn = tn
		num = self.pnum(count)
		if not self.cmd:
			rate = me.rate(self.data["data_size"],total=self.size,append="bytes")
		else:
			rate = me.rate(count,total=args.num_records)
			pass
		print(f"Loaded: {num} {rate}")
		return self


	def process_line(self,line):
		self.data["data_size"] += len(line)
		self.data["record_count"] += 1
		self.parent.record_count += 1
		if 0 == self.data["record_count"] % self.args.min_record_check:
			self.show_progress()
			pass
		try:
			self.count_attribs(json.loads(line))
		except json.decoder.JSONDecodeError as e:
			print("ERROR on line %s" %(self.data["record_count"]))
			print("Line:\n%s" %(line))
			self.show_progress()
			raise e
		return self

	def attr_info(self):
		# For some reason, the record_count is one ahead of where it should be when this is called.
		records = self.data["record_count"] -1
		for attr,inf in self.attribs.items():
			if "count" in inf:
				count = inf["count"]
				size = inf["size"]
				#inf["average_size"] = size / count
				#inf["average_size_per_record"] = size / records
				inf["prevalence"] = float("%0.8f" %(count / records))
				if "types" in inf:
					for vtype,data in inf["types"].items():
						data["p_record"] = float("%0.8f" %(data["count"] / records))
						data["p_attrib"] = float("%0.8f" %(data["count"] / count))
						if "bool" == vtype:
							data["p_true"] = float("%0.8f" %(data["true"] / data["count"]))
							data["p_false"] = float("%0.8f" %(data["false"] / data["count"]))
							pass
						pass
					pass
				pass
			pass
		print(f"Saving info to '{self.json_file}'")
		with open(self.json_file,'w') as fh:
			try:
				json.dump(self.data,fh,indent=2,sort_keys=True)
			except:
				print(self.data)
				raise
			pass
		return self


	def _proc_fh(self,fh):
		for line in fh:
			try:
				self.process_line(line)
			except json.decoder.JSONDecodeError as e:
				print("ERROR in JSON format, aborting load for this file.")
				return self.attr_info()
			pass
		return self.attr_info()

	def proc_from_cmd(self):
		if self.processed:
			return self
		self.cmd = self.data["subprocess"]
		self.cmd.append(self.data["file_name"])
		print(f"Running: {self.cmd}")
		proc = subprocess.Popen(
			self.cmd,
			stdout=subprocess.PIPE,
			universal_newlines=True
			)
		return self._proc_fh(proc.stdout)

	def process(self):
		if self.cmd:
			return self.proc_from_cmd()
		with open(self.full_filename,'r') as fh:
			return self._proc_fh(fh)
		return self
	pass

class PushShiftInfo(PushShiftBase):

	def __init__(self,args):
		super().__init__()
		self.args = args
		self.directory = args.directory
		self.tn = datetime.datetime.now()
		self.file_count = 0
		self.total_size = 0
		self.record_count = 0
		self.files = []
		#print(['self.args.files',self.args.files])
		for fname in self.args.files:
			self.prep_file(fname)
			pass
		if self.directory is not None:
			self.prep_dir(self.directory)
			pass
		print(f"Will process a total of {self.file_count} files for {me.pbytes(self.total_size)}.")
		pass

	def prep_file(self,filename):
		psfile = PushShiftFile(self,filename)
		self.files.append(psfile)
		self.file_count += 1
		self.total_size += psfile.size
		pass

	def prep_dir(self,directory):
		if not os.path.exists(self.directory):
			print("ERROR: Could not find '%s'" %(self.directory))
			exit()
			pass
		print(f"Working on '{directory}' ...")
		count = 0
		total_size = 0
		for (dirpath,dirnames,filenames) in os.walk(directory):
			for filename in filenames:
				full_filename = os.path.realpath(os.path.join(dirpath,filename))
				self.prep_file(full_filename)
			pass
		pass

	def process(self):
		for ofile in self.files:
			ofile.process()
			pass
		pass

def main():
	parser = argparse.ArgumentParser(description='Build info about data from PushShift.io files.')
	parser.add_argument('files', nargs='?', default=[], action='append', help="Files to process.")
	parser.add_argument('--debug', '-d', default=False, action='store_true', dest='debug', help="Turn debugging on.")
	parser.add_argument('--dir', '-D', default=None, dest='directory', help="Process files in this directory.")
	parser.add_argument('--min-record-check', '-mr', default=5, dest='min_record_check', type=int,help="To speed things up, we only check if --min-save-secs after this many thousand records. Default: 5 (i.e., 5,000)")
	parser.add_argument('--min-save-secs', '-ms', default=10, dest='min_save_secs', type=int,help="The minimum number of secods which must pass before we save progress. Default: 10")
	parser.add_argument('--save-progress-each', '-pp', default=50, dest='save_progress_each', type=int,help="Number of --min-record-check for printing what we have so far with attribute information.")
	parser.add_argument('--num-records', '-nr', default=None, dest='num_records', type=int,help="Number of records expected. Used to estimate time remaining.")
	parser.add_argument('--quiet', '-q', default=0, dest='quiet', action='count',help="Decrease verbosity. Can have multiple.")
	parser.add_argument('--verbose', '-v', default=0, dest='verbosity', action='count',help="Increase verbosity. Can have multiple.")

	args = parser.parse_args()
	args.verbosity = 1 + args.verbosity - args.quiet
	args.min_record_check = args.min_record_check * 1000
	if args.save_progress_each is not None:
		args.save_progress_each = args.save_progress_each * args.min_record_check
		pass
	if args.verbosity > 0:
		print(f"Settings:")
		print(f" - {me.pnum(args.min_record_check)} lines before save/print.")
		print(f" - {me.psecs(args.min_save_secs)} minimum between progress output.")
		print(f" - Save/print after {me.pnum(args.save_progress_each)} records if {me.psecs(args.min_save_secs)} have passed.")
		pass
	args.timestr = time.strftime("%Y%m%d-%H%M%S")
	pinfo = PushShiftInfo(args)
	pinfo.process()
	pass

if __name__ == "__main__":
	main()
	sys.exit(0)
	pass
